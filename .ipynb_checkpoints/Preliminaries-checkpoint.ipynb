{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "Data preprocessing in order to feed our CNN. The following considerations are taking into account:\n",
    "\n",
    "* To read the data, Uproot is faster than Pyroot. However, we do not know if the software can be installed properly at CUDA and CIEMAT computers. \n",
    "* Software to reduce the size of the images, but keeping the signal and important caracteristics.\n",
    "* A method to store this data efficiently. Probably png or csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## dependencies ###########\n",
    "import uproot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = uproot.open(\"0-RecoFull-Parser.root\")\n",
    "print(\"the data contains in the file has the following format: \",file[file.keys()[0]].keys())\n",
    "print(\"We can access the data using\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=file[\"analysistree\"][\"anatree\"] \n",
    "tree.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree.array(b'RecoWaveform_Channel')[98].shape) ## 1229 channels\n",
    "print(tree.array( b'RecoWaveform_NTicks')[98]) ## each channel 1667 ticks , the explanatory pdf is wrong!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It seems that theere are 1229 channels and 1667 ticks. \n",
    "* probably first view from 0 to 279 and second the rest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADC = tree.array( b'RecoWaveform_ADC')\n",
    "NChannel=tree.array(b'RecoWaveforms_NumberOfChannels')\n",
    "Nticks=tree.array(b'RecoWaveform_NumberOfTicksInAllChannels')\n",
    "NTracks=tree.array(b'NumberOfTracks')\n",
    "w , h = int(NChannel[0]) , int(Nticks[0]/NChannel[0])\n",
    "print(w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im=ADC[56].reshape((w,h))\n",
    "v1=im[0:279,:]\n",
    "fig = plt.figure(frameon = False)\n",
    "plt.imshow(v1.T,cmap = 'jet',interpolation='none')\n",
    "fig.set_size_inches(30, 40)##grey scale\n",
    "plt.savefig('big.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool(im, h, w):\n",
    "    #####the imputs#####\n",
    "    # im.shape must be a matrix of(width, height)\n",
    "    # w and h are the output weight and height respectively .\n",
    "    \n",
    "#### preliminaries###\n",
    "    h_step=im.shape[0]//h\n",
    "    w_step=im.shape[1]//w\n",
    "    #print(\"we have lost\", (im.shape[1]%w)*(im.shape[0]%h), \"pixels along the way\")\n",
    "    \n",
    "    reduced_im=np.zeros((h,w)) ##the new reduced matrix is initialized with zeros\n",
    "    \n",
    "    \n",
    "    ########The algorithm#########\n",
    "    for i in range(0,h): #loop over h\n",
    "        for j in range(0,w): #loop over w\n",
    "            pool=im[i*h_step:h_step*(i+1),j*w_step:(j+1)*w_step]\n",
    "            reduced_im[i,j]=np.max(pool)\n",
    "            \n",
    "            \n",
    "    return reduced_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpoolmod(im, h, w):\n",
    "    # observacions, modifications to account for issues regarding h_step ~ 1\n",
    "    #####the imputs#####\n",
    "    # im.shape must be a matrix of(width, height)\n",
    "    # w and h are the output weight and height respectively .\n",
    "    \n",
    "#### preliminaries###\n",
    "    h_step=im.shape[0]//h\n",
    "    w_step=im.shape[1]//w\n",
    "    #print(\"we have lost\", (im.shape[1]%w)*(im.shape[0]%h), \"pixels along the way\")\n",
    "    \n",
    "    reduced_im=np.zeros((h,w)) ##the new reduced matrix is initialized with zeros\n",
    "    extra_pixels=v1.shape[0]-(v1.shape[0]//200)*200\n",
    "    loss_h = (im.shape[0]//200 *200)/im.shape[0] ##the percented of the image that we will lose\n",
    "    print(loss_h)\n",
    "    count=0\n",
    "    ########The algorithm#########\n",
    "    for i in range(0,h): #loop over h\n",
    "        for j in range(0,w): #loop over w\n",
    "            r=np.random.uniform()\n",
    "            #print(count,r)\n",
    "            if r>extra_pixels/h/w and count<extra_pixels:\n",
    "                pool=im[(i+count)*h_step:h_step*(i+1+count),(j)*w_step:(j+1)*w_step]\n",
    "                reduced_im[i,j]=np.max(pool)\n",
    "            if r<extra_pixels/h/w and count<extra_pixels:\n",
    "                pool=im[(i+count)*h_step:h_step*(i+1+count),(j)*w_step:(j+1)*w_step]\n",
    "                reduced_im[i,j]=np.max(pool)\n",
    "                count=count+1     \n",
    "    return reduced_im ,count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1.shape[0]-v1.shape[0]//200*200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "v1red=maxpool(v1,200,200)\n",
    "fig = plt.figure(frameon = False)\n",
    "plt.imshow(v1red.T,cmap = 'jet',interpolation='none')\n",
    "fig.set_size_inches(10, 10) ##grey scale\n",
    "plt.savefig('small.png')\n",
    "\n",
    "v1redmu, count=maxpoolmod(v1,200,200)\n",
    "print(count)\n",
    "fig = plt.figure(frameon = False)\n",
    "plt.imshow(v1redmu.T,cmap = 'jet',interpolation='none')\n",
    "fig.set_size_inches(10, 10) ##grey scale\n",
    "plt.savefig('small.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observaciones:\n",
    "* the algorithm only works approximately if h and w are <<< im.shape . Otherwise, the algorithm will cut the image. \n",
    "\n",
    "* In order to account for this issue, what can be done is \n",
    "\n",
    "    1. reduce only the big axis, the one with\n",
    "    2. modify the algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "v1red=maxpool(v1,200,200)\n",
    "fig = plt.figure(frameon = False)\n",
    "plt.imshow(v1red.T,cmap = 'jet',interpolation='none')\n",
    "fig.set_size_inches(10, 10) ##grey scale\n",
    "plt.savefig('small.png')\n",
    "\n",
    "v1red=maxpoolmod(v1,200,200)\n",
    "fig = plt.figure(frameon = False)\n",
    "plt.imshow(v1red.T,cmap = 'jet',interpolation='none')\n",
    "fig.set_size_inches(10, 10) ##grey scale\n",
    "plt.savefig('small.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considerations: file size\n",
    "In order to save memory, our data set must me made of these images. It can be stored in a cv file, or in a root tree. We will see how efficient is the root tree. Options: \n",
    "\n",
    "* use csv files with delimiter ',' : 200x200 img is ~900K\n",
    "* use numpy.save : 200x200 img is ~300K\n",
    "* use ROOT trees: 200x200 img is ~33K\n",
    "* use png images: The data is not properly conserved, we do not have the numerical values but rather a png image that approximate this values. \n",
    "\n",
    "As far as disc memory is concerned, probably the best option to tackle this problem is using ROOT trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('savenp',v1red) ### \n",
    "np.savetxt(\"foo.csv\", v1red, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ROOT import TFile, TTree\n",
    "import numpy as np\n",
    "\n",
    "f = TFile('example.root', 'recreate')\n",
    "t = TTree('mytree', 'example tree')\n",
    "\n",
    "t.Branch('myarray', v1red, 'myarray[200][200]/D')\n",
    "print(v1red.flatten().shape)\n",
    "\n",
    "t.Fill()\n",
    "\n",
    "f.Write()\n",
    "f.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "import numpy as np\n",
    "\n",
    "tfile = ROOT.TFile(\"example.root\")\n",
    "ttree = tfile.mytree\n",
    "\n",
    "nentries = 1\n",
    "for i in range(nentries):\n",
    "    ttree.GetEntry(i)\n",
    "    print(ttree.myarray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1red.flatten()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(frameon = False)\n",
    "plt.imshow(v1red.flatten().reshape(200,200).T,cmap = 'jet',interpolation='none')\n",
    "fig.set_size_inches(10, 10) ##grey scale\n",
    "plt.savefig('small.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=uproot.open(\"example.root\")\n",
    "tree=file[b'mytree;1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im=tree.array( b'myarray')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(im.shape)\n",
    "print(v1red.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(frameon = False)\n",
    "plt.imshow(im.T,cmap = 'jet',interpolation='none')\n",
    "fig.set_size_inches(10, 10) ##grey scale\n",
    "plt.savefig('small.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reduction algorithim must be uploaded into lxplus and then download the reduced data. Consequently, 1000 $e^{-}$ and 1000 $\\mu^{-}$ waveforms must be around 60MB and 1 million waveforms 30 GB. I believe this 30 GB is a very reasonable number. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to see if the image reduction algorithm also works for electrons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = uproot.open(\"/Users/dan/CIEMAT/ROOT/ROOT_try/electrons/0-RecoFull-Parser.root\")\n",
    "tree=file[\"analysistree\"][\"anatree\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADC = tree.array( b'RecoWaveform_ADC')\n",
    "NChannel=tree.array(b'RecoWaveforms_NumberOfChannels')\n",
    "Nticks=tree.array(b'RecoWaveform_NumberOfTicksInAllChannels')\n",
    "NTracks=tree.array(b'NumberOfTracks')\n",
    "w , h = int(NChannel[0]) , int(Nticks[0]/NChannel[0])\n",
    "print(w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "im=ADC[61].reshape((w,h))\n",
    "v1=im[0:279,:]\n",
    "fig = plt.figure(frameon = False)\n",
    "plt.imshow(v1.T,cmap = 'jet',interpolation='none')\n",
    "fig.set_size_inches(30, 40) ##grey scale\n",
    "plt.savefig('big.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1red=maxpool(v1,100,100)\n",
    "fig = plt.figure(frameon = False)\n",
    "plt.imshow(v1red.T,cmap = 'jet',interpolation='none')\n",
    "fig.set_size_inches(10, 10) ##grey scale\n",
    "plt.savefig('small.png')\n",
    "\n",
    "v1rede, count =maxpoolmod(v1,100,100)\n",
    "print(count)\n",
    "fig = plt.figure(frameon = False)\n",
    "plt.imshow(v1rede.T,cmap = 'jet',interpolation='none')\n",
    "fig.set_size_inches(10, 10) ##grey scale\n",
    "plt.savefig('small.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "100*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "Now our data is ready to feed our Deep Neural networks.\n",
    "\n",
    "Conviene reducir a 100x100 pixeles\n",
    "\n",
    "* bloque convolutivo\n",
    " 1. kernel(5...7...9)\n",
    " 2. bajar después+pooling (2x2)\n",
    "* salida\n",
    " 1. confusion matrix\n",
    " 2. evolución del fitness en función de la época\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
